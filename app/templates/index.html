<!doctype html>
<html>
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover,maximum-scale=1"/>
  <title>Indoor Nav ‚Äì Web</title>
  <style>
    :root{--bg:#0b0b0b;--fg:#eaeaea;--card:#121212;--blue:#3b82f6;--muted:#8b8b8b}
    *{box-sizing:border-box}
    body{margin:0;background:var(--bg);color:var(--fg);font-family:-apple-system,system-ui,Segoe UI,Arial}
    .wrap{display:grid;gap:12px;padding:12px;max-width:900px;margin:0 auto}
    .toolbar{display:flex;gap:8px;align-items:center;flex-wrap:wrap}
    button{padding:10px 14px;border:none;border-radius:12px;background:var(--blue);color:#fff;font-weight:700}
    button[disabled]{opacity:.55}
    input[type=text]{flex:1;min-width:180px;padding:10px;border-radius:12px;border:1px solid #2a2a2a;background:#111;color:var(--fg)}
    .pill{display:inline-block;padding:6px 10px;border-radius:999px;background:#222;color:#ddd;font-weight:600;user-select:none}
    video,canvas{width:100%;max-height:48vh;border-radius:12px;background:#111}
    .hud{padding:14px;border-radius:12px;background:var(--card);line-height:1.5}
    .row{display:flex;gap:8px;flex-wrap:wrap}
    .k{color:#9bb8ff}
    .mono{font-family:ui-monospace, SFMono-Regular, Menlo, monospace;word-break:break-word;white-space:pre-wrap}
  </style>
</head>
<body>
<div class="wrap">
  <div class="toolbar">
    <button id="voiceBtn">üéô Enable Voice</button>
    <button id="startBtn" disabled>üé• Start</button>
    <button id="stopBtn" disabled>‚èπ Stop</button>
    <div id="goal" class="pill" aria-live="polite" title="Current goal">Goal: ‚Äî</div>
  </div>


  <video id="v" playsinline muted autoplay></video>
  <canvas id="c" style="display:none"></canvas>

  <div class="hud">
    <div class="row"><div class="k">next_action:</div><div id="nextAction">‚Äî</div></div>
    <div class="row"><div class="k">timestamp:</div><div id="ts">‚Äî</div></div>
    <div class="row"><div class="k">goal:</div><div id="goalHud">‚Äî</div></div>
    <div class="row"><div class="k">goal_visible:</div><div id="goalVisible">‚Äî</div></div>
    <div class="row"><div class="k">goal_side:</div><div id="goalSide">‚Äî</div></div>
    <div class="row"><div class="k">goal_distance:</div><div id="goalDistance">‚Äî</div></div>
  </div>
</div>

<script>
let running=false, timer=null;
let v=document.getElementById('v'), c=document.getElementById('c');
let startBtn=document.getElementById('startBtn'), stopBtn=document.getElementById('stopBtn');
let voiceBtn=document.getElementById('voiceBtn');

let goalEl=document.getElementById('goal');
let goalHud=document.getElementById('goalHud');
let CURRENT_GOAL = ""; 

let nextAction=document.getElementById('nextAction'),
    tsEl=document.getElementById('ts'),
    goalVisibleEl=document.getElementById('goalVisible'),
    goalSideEl=document.getElementById('goalSide'),
    goalDistanceEl=document.getElementById('goalDistance');

let voiceStream=null, mediaRec=null, voiceTimer=null; 
let ttsReady = false;
let lastSpokenGoal = "";
const STEP_DELAY_MS = 3000;
let stepCount = 0;                
let pendingGoalHint = false;       
let lastGoalSide = "none";         


function primeTTS(){
  if (ttsReady) return;
  if (!('speechSynthesis' in window)) {
    console.log('speechSynthesis not supported');
    ttsReady = true;
    return;
  }
  ttsReady = true;
  try{
    const u = new SpeechSynthesisUtterance('');
    u.volume = 0.0;     
    u.rate = 1.0;
    u.pitch = 1.0;

    const _ = speechSynthesis.getVoices();
    speechSynthesis.speak(u);
  }catch(e){
    console.log('primeTTS error', e);
  }
}

function speak(text){
  if (!('speechSynthesis' in window)) {
    console.log('speechSynthesis not available');
    return;
  }
  try{
    const u = new SpeechSynthesisUtterance(text);
    u.lang = 'en-US'; 
    u.rate = 1.0;
    u.pitch = 1.0;
    
    speechSynthesis.speak(u);
  }catch(e){
    console.log('TTS error', e);
  }
}

function speakNow(text){
  if (!('speechSynthesis' in window)) return;
  try{
    speechSynthesis.cancel();
    const u = new SpeechSynthesisUtterance(text);
    u.lang = 'en-US';
    u.rate = 1.0;
    u.pitch = 1.0;
    speechSynthesis.speak(u);
  }catch(e){
    console.log('TTS error', e);
  }
}


function setGoal(text){
  CURRENT_GOAL = (text || "").trim();
  const display = CURRENT_GOAL ? ("Goal: " + CURRENT_GOAL) : "Goal: ‚Äî";
  if (goalEl)  goalEl.textContent  = display;
  if (goalHud) goalHud.textContent = CURRENT_GOAL || '‚Äî';
  try{ localStorage.setItem('goal_text', CURRENT_GOAL); }catch(_){}
}

function getGoal(){
  return CURRENT_GOAL || "";
}


try{
  const savedGoal = localStorage.getItem('goal_text');
  if (savedGoal) setGoal(savedGoal);
}catch(_){}
fetch('/current_goal').then(r=>r.json()).then(js=>{
  if (js && typeof js.current_goal === 'string' && js.current_goal.trim()){
    setGoal(js.current_goal.trim());
  }
}).catch(()=>{});


async function startWavFallback(stream){
  const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
  const src = audioCtx.createMediaStreamSource(stream);
  const processor = audioCtx.createScriptProcessor(4096, 1, 1);

  const chunks = [];      
  let lastSend = performance.now();
  src.connect(processor);
  processor.connect(audioCtx.destination);
  processor.onaudioprocess = (e)=>{
    const input = e.inputBuffer.getChannelData(0);
    chunks.push(new Float32Array(input)); 
    if (performance.now() - lastSend > 3500) { 
      lastSend = performance.now();
      const wavBlob = floatChunksToWav(chunks.splice(0, chunks.length), audioCtx.sampleRate);
      sendWavChunk(wavBlob); 
    }
  };

  async function sendWavChunk(blob){
      const fd = new FormData();
      fd.append('audio', blob, 'chunk.wav');
      fd.append('goal_ctx', getGoal());
      try{
        const r = await fetch('/asr', { method:'POST', body: fd });
        const data = await r.json();
    
        if (data.intent === 'start') {
          if (!running) {
            startBtn.click();

            speakNow('Navigation started');
          }
        } else if (data.intent === 'stop') {
          if (running) {
            speakNow('Navigation ended');
            stopBtn.click();  
          }
        } else if (data.intent === 'set_goal' && typeof data.goal === 'string') {
          setGoal(data.goal);
          if (data.goal && data.goal !== lastSpokenGoal) {
            speakNow('New goal: ' + data.goal);
            lastSpokenGoal = data.goal;
          }
          pendingGoalHint = true;
        }

      } catch (err) {
        console.log(err);
      }
    }


  function floatChunksToWav(float32Arrays, sampleRate){

  let length = 0;
  for (const a of float32Arrays) length += a.length;
  const pcm = new Float32Array(length);
  let o = 0; for (const a of float32Arrays){ pcm.set(a, o); o += a.length; }

  const pcm16 = new Int16Array(pcm.length);
  for (let i=0;i<pcm.length;i++){
    let s = Math.max(-1, Math.min(1, pcm[i]));
    pcm16[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
  }

  const bytesPerSample = 2, numCh = 1;
  const blockAlign = numCh * bytesPerSample;
  const byteRate = sampleRate * blockAlign;
  const buffer = new ArrayBuffer(44 + pcm16.length * 2);
  const view = new DataView(buffer);
  let p = 0;
  function wStr(s){ for(let i=0;i<s.length;i++) view.setUint8(p++, s.charCodeAt(i)); }
  function w32(v){ view.setUint32(p, v, true); p+=4; }
  function w16(v){ view.setUint16(p, v, true); p+=2; }

  wStr('RIFF'); w32(36 + pcm16.length*2); wStr('WAVE');
  wStr('fmt '); w32(16); w16(1); w16(numCh); w32(sampleRate);
  w32(byteRate); w16(blockAlign); w16(16);
  wStr('data'); w32(pcm16.length*2);
  for(let i=0;i<pcm16.length;i++) view.setInt16(p, pcm16[i], true), p+=2;

  return new Blob([view], { type:'audio/wav' });
}

}



voiceBtn.addEventListener('click', async ()=>{
  primeTTS();
  try{

    const av = await navigator.mediaDevices.getUserMedia({
      audio:true,
      video:{ facingMode:{ ideal:"environment" } }
    });

    av.getVideoTracks().forEach(t=>t.stop());
    const aStream = new MediaStream(av.getAudioTracks());


    const ua = navigator.userAgent;
    const isSafari = /Safari/.test(ua) && !/Chrome/.test(ua);
    const isIOS = /iPhone|iPad|iPod/.test(ua);

    if (isIOS || isSafari) {
      await startWavFallback(aStream);
      voiceBtn.disabled = true;
      startBtn.disabled = false;
      return;
    }

    let mime = '';
    if (window.MediaRecorder && MediaRecorder.isTypeSupported) {
      if (MediaRecorder.isTypeSupported('audio/webm;codecs=opus')) mime = 'audio/webm;codecs=opus';
      else if (MediaRecorder.isTypeSupported('audio/webm')) mime = 'audio/webm';
      else if (MediaRecorder.isTypeSupported('audio/mp4')) mime = 'audio/mp4';
    }

    if (window.MediaRecorder && mime){
      mediaRec = new MediaRecorder(aStream, { mimeType: mime });
      mediaRec.ondataavailable = async (e)=>{
          if (!e.data || e.data.size < 4096) return;
          const fd = new FormData();
          const filename =
            e.data.type.includes('webm') ? 'chunk.webm' :
            e.data.type.includes('mp4')  ? 'chunk.m4a' : 'chunk.bin';
          fd.append('audio', e.data, filename);
          fd.append('goal_ctx', getGoal());
        
          try {
            const r = await fetch('/asr', { method:'POST', body: fd });
            const data = await r.json();
        
            if (data.intent === 'start') {
              if (!running) {
                startBtn.click();

                speakNow('Navigation started');
              }
            } else if (data.intent === 'stop') {
              if (running) {
                speakNow('Navigation ended');
                stopBtn.click();  
              }
            } else if (data.intent === 'set_goal' && typeof data.goal === 'string') {
              setGoal(data.goal);
              if (data.goal && data.goal !== lastSpokenGoal) {
                speakNow('New goal: ' + data.goal);
                lastSpokenGoal = data.goal;
              }
              pendingGoalHint = true;
            }
          } catch (err) {
            console.log(err);
          }
        };
      mediaRec.start(3500);
      voiceTimer = setInterval(()=>{ if(mediaRec && mediaRec.state==='recording') mediaRec.requestData(); }, 3600);
      voiceBtn.disabled = true; startBtn.disabled = false;
      return;
    }

    await startWavFallback(aStream);
    voiceBtn.disabled = true; startBtn.disabled = false;
  }catch(e){
    alert('Microphone/Camera permission failed: ' + e.message);
  }
});



function logErr(e){ console.log(e); }


async function getCam(){

  const constraints = {
    video: {
      facingMode: { ideal: "environment" }, width: { ideal: 1280 }, height: { ideal: 720 }
    },
    audio: false
  };
  try{
    return await navigator.mediaDevices.getUserMedia(constraints);
  }catch(e){

    return await navigator.mediaDevices.getUserMedia({ video:true, audio:false });
  }
}


function canvasToBlobSafe(canvas, type="image/jpeg", quality=0.72){
  return new Promise((resolve)=>{
    if(canvas.toBlob){
      canvas.toBlob(b=>resolve(b), type, quality);
    }else{
      const dataURL = canvas.toDataURL(type, quality);
      fetch(dataURL).then(r=>r.blob()).then(resolve).catch(()=>resolve(null));
    }
  });
}

startBtn.addEventListener('click', async ()=>{
  if(running) return;
  primeTTS();
  try{
    const stream = await getCam();
    v.setAttribute('playsinline',''); 
    v.muted = true;                   
    v.srcObject = stream;
    await v.play();
    running = true; startBtn.disabled=true; stopBtn.disabled=false;
    loop();
  }catch(e){ alert('Camera permission failed: '+e.message); }
});

stopBtn.addEventListener('click', ()=>{
  running=false; if(timer) clearTimeout(timer);
  if(v.srcObject){ v.srcObject.getTracks().forEach(t=>t.stop()); v.srcObject=null; }
  startBtn.disabled=false; stopBtn.disabled=true;
});

async function loop(){
  if (!running) return;
  const w = v.videoWidth, h = v.videoHeight;
  if (w && h) {

    const scale = 0.6;
    c.width  = Math.floor(w * scale);
    c.height = Math.floor(h * scale);
    const ctx = c.getContext('2d', { willReadFrequently:true });
    ctx.drawImage(v, 0, 0, c.width, c.height);
    const blob = await canvasToBlobSafe(c, 'image/jpeg', 0.70);

    
    if (blob) {
      await send(blob);
    }
  }


  if (!running) return;


  // const baseDelay = Math.max(333, 1000 / Math.max(1, fps));
  const totalDelay = STEP_DELAY_MS;

  timer = setTimeout(loop, totalDelay);
}


async function send(blob){
  const fd=new FormData();
  fd.append('image', blob, 'frame.jpg');
  fd.append('goal', getGoal());
  try{
    const r=await fetch('/infer',{method:'POST',body:fd});
    if(!r.ok) throw new Error('HTTP '+r.status);
    const data=await r.json();


    const action = data.next_action || '‚Äî';
    nextAction.textContent = action;
    tsEl.textContent = data.timestamp || '‚Äî';
    const gv = !!data.goal_visible;
    const gs = (data.goal_side || 'none').toLowerCase();
    const gd = (data.goal_distance || 'unknown').toString();

    if (goalVisibleEl)  goalVisibleEl.textContent  = gv ? 'true' : 'false';
    if (goalSideEl)     goalSideEl.textContent     = gs;
    if (goalDistanceEl) goalDistanceEl.textContent = gd;

    

    // const gv = !!data.goal_visible;
    // const gs = (data.goal_side || 'none').toLowerCase();
    

    if (!gv) {

        nextAction.textContent = 'stop';
    
        if ('speechSynthesis' in window) {
          speechSynthesis.cancel();
          speak('Your destination is not in view yet');
        }

        return;
      }


    const utterances = [];


    if (data.next_action && typeof data.next_action === 'string') {
      const act = data.next_action;
      let phrase = null;
      switch (act) {
        case 'forward':
          phrase = 'Step forward';
          break;
        case 'forward-left':
          phrase = 'Step slightly left and forward';
          break;
        case 'forward-right':
          phrase = 'Step slightly right and forward';
          break;
        case 'stop':
          if (data.goal_reached) {
            phrase = 'You have reached your destination';
          } else {
            phrase = 'Stop. Obstacle ahead';
          }
          break;
      }
      if (phrase) utterances.push(phrase);
    }


    stepCount += 1;

    let dirText = null;
    if (gs === 'left')   dirText = 'Your destination is ahead on your left';
    if (gs === 'center') dirText = 'Your destination is straight ahead';
    if (gs === 'right')  dirText = 'Your destination is ahead on your right';

    if (dirText && (pendingGoalHint || (stepCount % 3 === 0))) {
      utterances.push(dirText);
      pendingGoalHint = false;
      lastGoalSide = gs;
    }


    if (utterances.length > 0 && 'speechSynthesis' in window) {
      speechSynthesis.cancel();
      for (const t of utterances) {
        speak(t);  
      }
    }

  }catch(e){ logErr(e); }
}


</script>
</body>
</html>
